{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estudo prático da estrutura das redes neurais artificiais - Classificação binária\n",
    "\n",
    "#### Sabrina Otoni da Silva - 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as k\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = pd.read_csv('entradas_breast.csv')\n",
    "classe = pd.read_csv('saidas_breast.csv')\n",
    "\n",
    "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, classe, test_size=0.25)\n",
    "\n",
    "classificador = Sequential([\n",
    "               tf.keras.layers.Dense(units=16, activation = 'relu', kernel_initializer = 'random_uniform', input_dim=30),\n",
    "               tf.keras.layers.Dense(units=16, activation = 'relu', kernel_initializer = 'random_uniform'),\n",
    "               tf.keras.layers.Dense(units=1, activation = 'sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "43/43 [==============================] - 1s 2ms/step - loss: 1.0349 - binary_accuracy: 0.5516\n",
      "Epoch 2/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.4675 - binary_accuracy: 0.7324\n",
      "Epoch 3/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3994 - binary_accuracy: 0.8122\n",
      "Epoch 4/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.4492 - binary_accuracy: 0.7958\n",
      "Epoch 5/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3661 - binary_accuracy: 0.8404\n",
      "Epoch 6/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.4135 - binary_accuracy: 0.8404\n",
      "Epoch 7/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3605 - binary_accuracy: 0.8568\n",
      "Epoch 8/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3548 - binary_accuracy: 0.8803\n",
      "Epoch 9/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5280 - binary_accuracy: 0.7934\n",
      "Epoch 10/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3189 - binary_accuracy: 0.8638\n",
      "Epoch 11/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3465 - binary_accuracy: 0.8709\n",
      "Epoch 12/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3532 - binary_accuracy: 0.8662\n",
      "Epoch 13/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5017 - binary_accuracy: 0.8263\n",
      "Epoch 14/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3278 - binary_accuracy: 0.8709\n",
      "Epoch 15/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3572 - binary_accuracy: 0.8732\n",
      "Epoch 16/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.4277 - binary_accuracy: 0.8263\n",
      "Epoch 17/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3370 - binary_accuracy: 0.8850\n",
      "Epoch 18/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3527 - binary_accuracy: 0.8779\n",
      "Epoch 19/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3409 - binary_accuracy: 0.8803\n",
      "Epoch 20/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3097 - binary_accuracy: 0.8850\n",
      "Epoch 21/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3210 - binary_accuracy: 0.8709\n",
      "Epoch 22/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3261 - binary_accuracy: 0.8850\n",
      "Epoch 23/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3694 - binary_accuracy: 0.8521\n",
      "Epoch 24/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3146 - binary_accuracy: 0.8873\n",
      "Epoch 25/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2849 - binary_accuracy: 0.8991\n",
      "Epoch 26/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3466 - binary_accuracy: 0.8521\n",
      "Epoch 27/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3645 - binary_accuracy: 0.8779\n",
      "Epoch 28/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3458 - binary_accuracy: 0.8685\n",
      "Epoch 29/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2860 - binary_accuracy: 0.8920\n",
      "Epoch 30/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2868 - binary_accuracy: 0.8920\n",
      "Epoch 31/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3074 - binary_accuracy: 0.8779\n",
      "Epoch 32/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3692 - binary_accuracy: 0.8685\n",
      "Epoch 33/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3110 - binary_accuracy: 0.8779\n",
      "Epoch 34/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3588 - binary_accuracy: 0.8615\n",
      "Epoch 35/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.4780 - binary_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3694 - binary_accuracy: 0.8662\n",
      "Epoch 37/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3546 - binary_accuracy: 0.8756\n",
      "Epoch 38/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.4207 - binary_accuracy: 0.8662\n",
      "Epoch 39/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.4937 - binary_accuracy: 0.8779\n",
      "Epoch 40/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.4331 - binary_accuracy: 0.8967\n",
      "Epoch 41/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2666 - binary_accuracy: 0.8873\n",
      "Epoch 42/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3503 - binary_accuracy: 0.8638\n",
      "Epoch 43/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3073 - binary_accuracy: 0.8897\n",
      "Epoch 44/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2740 - binary_accuracy: 0.8920\n",
      "Epoch 45/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2920 - binary_accuracy: 0.8803\n",
      "Epoch 46/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2965 - binary_accuracy: 0.8967\n",
      "Epoch 47/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2805 - binary_accuracy: 0.8897\n",
      "Epoch 48/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3313 - binary_accuracy: 0.8803\n",
      "Epoch 49/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3000 - binary_accuracy: 0.8803\n",
      "Epoch 50/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3692 - binary_accuracy: 0.8638\n",
      "Epoch 51/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4608 - binary_accuracy: 0.8545\n",
      "Epoch 52/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3053 - binary_accuracy: 0.8850\n",
      "Epoch 53/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.6636 - binary_accuracy: 0.8286\n",
      "Epoch 54/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3569 - binary_accuracy: 0.8732\n",
      "Epoch 55/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2745 - binary_accuracy: 0.8732\n",
      "Epoch 56/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2776 - binary_accuracy: 0.8944\n",
      "Epoch 57/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2980 - binary_accuracy: 0.8873\n",
      "Epoch 58/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4034 - binary_accuracy: 0.8662\n",
      "Epoch 59/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5410 - binary_accuracy: 0.8380\n",
      "Epoch 60/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.7425 - binary_accuracy: 0.8732\n",
      "Epoch 61/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3157 - binary_accuracy: 0.8850\n",
      "Epoch 62/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2787 - binary_accuracy: 0.8944\n",
      "Epoch 63/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3130 - binary_accuracy: 0.8873\n",
      "Epoch 64/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4632 - binary_accuracy: 0.8568\n",
      "Epoch 65/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2913 - binary_accuracy: 0.8756\n",
      "Epoch 66/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3551 - binary_accuracy: 0.8944\n",
      "Epoch 67/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3331 - binary_accuracy: 0.8850\n",
      "Epoch 68/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.4055 - binary_accuracy: 0.8615\n",
      "Epoch 69/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3611 - binary_accuracy: 0.8850\n",
      "Epoch 70/100\n",
      "43/43 [==============================] - 0s 968us/step - loss: 0.8228 - binary_accuracy: 0.8380\n",
      "Epoch 71/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4113 - binary_accuracy: 0.8615\n",
      "Epoch 72/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4184 - binary_accuracy: 0.8779\n",
      "Epoch 73/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.4295 - binary_accuracy: 0.8803\n",
      "Epoch 74/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4184 - binary_accuracy: 0.8732\n",
      "Epoch 75/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4564 - binary_accuracy: 0.8685\n",
      "Epoch 76/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.5665 - binary_accuracy: 0.8615\n",
      "Epoch 77/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5371 - binary_accuracy: 0.8404\n",
      "Epoch 78/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4357 - binary_accuracy: 0.8592\n",
      "Epoch 79/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.5114 - binary_accuracy: 0.8498\n",
      "Epoch 80/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4580 - binary_accuracy: 0.8685\n",
      "Epoch 81/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4801 - binary_accuracy: 0.8474\n",
      "Epoch 82/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.6546 - binary_accuracy: 0.8404\n",
      "Epoch 83/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.5824 - binary_accuracy: 0.8451\n",
      "Epoch 84/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5073 - binary_accuracy: 0.8451\n",
      "Epoch 85/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.6731 - binary_accuracy: 0.8568\n",
      "Epoch 86/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5098 - binary_accuracy: 0.8451\n",
      "Epoch 87/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4114 - binary_accuracy: 0.8592\n",
      "Epoch 88/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.5106 - binary_accuracy: 0.8498\n",
      "Epoch 89/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5159 - binary_accuracy: 0.8427\n",
      "Epoch 90/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.6719 - binary_accuracy: 0.8310\n",
      "Epoch 91/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.4562 - binary_accuracy: 0.8826\n",
      "Epoch 92/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3810 - binary_accuracy: 0.8685\n",
      "Epoch 93/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.4261 - binary_accuracy: 0.8779\n",
      "Epoch 94/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4003 - binary_accuracy: 0.8568\n",
      "Epoch 95/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.6110 - binary_accuracy: 0.8803\n",
      "Epoch 96/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4384 - binary_accuracy: 0.8638\n",
      "Epoch 97/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3600 - binary_accuracy: 0.8967\n",
      "Epoch 98/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.5376 - binary_accuracy: 0.8826\n",
      "Epoch 99/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.5033 - binary_accuracy: 0.8615\n",
      "Epoch 100/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.5167 - binary_accuracy: 0.8427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2944a065010>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otimizador = tf.keras.optimizers.Adam(learning_rate = 0.001, weight_decay = 0.0001, clipvalue = 0.5)\n",
    "\n",
    "classificador.compile(optimizer = otimizador, loss = 'binary_crossentropy',\n",
    "                      metrics = ['binary_accuracy'])\n",
    "\n",
    "classificador.fit(previsores_treinamento, classe_treinamento,\n",
    "                  batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-1.04531214e-01, -1.10915914e-01, -1.63163587e-01,\n",
      "         6.10635802e-02, -1.22968420e-01,  1.31991073e-01,\n",
      "         6.59017339e-02, -4.84190211e-02,  1.20357163e-01,\n",
      "        -2.59578861e-02,  1.44198045e-01,  1.46997079e-01,\n",
      "         7.55535737e-02,  3.93782407e-02, -1.29439225e-02,\n",
      "        -5.48320785e-02],\n",
      "       [-9.30342972e-02, -1.98527217e-01, -5.42400219e-02,\n",
      "        -1.74055044e-02, -3.08072448e-01,  2.37119012e-02,\n",
      "         5.67957992e-03, -3.25319916e-02,  4.32547778e-02,\n",
      "        -1.01894345e-02,  2.72874951e-01, -2.94073652e-02,\n",
      "        -1.24002032e-01,  2.10220948e-01,  1.36659175e-01,\n",
      "        -2.18727529e-01],\n",
      "       [ 1.96520150e-01, -6.36120215e-02, -1.51972607e-01,\n",
      "        -3.48054357e-02, -3.56756174e-03, -4.51598056e-02,\n",
      "        -9.15048346e-02,  3.10902949e-02, -1.01244055e-01,\n",
      "         9.17708278e-02,  6.11947197e-03, -4.09077890e-02,\n",
      "        -2.29021758e-01,  1.38323888e-01, -1.69399288e-03,\n",
      "        -1.14324324e-01],\n",
      "       [ 7.81567022e-02,  3.76766846e-02, -4.17043418e-02,\n",
      "        -4.81470861e-02,  5.29274009e-02,  3.02035827e-02,\n",
      "        -2.84645278e-02,  1.30160069e-02,  8.82447511e-02,\n",
      "        -8.91645849e-02, -3.73289525e-03,  3.84819768e-02,\n",
      "        -3.00025847e-02, -1.18078133e-02,  1.19089134e-01,\n",
      "        -4.50445190e-02],\n",
      "       [-1.33004278e-01, -2.24389546e-02,  7.45035186e-02,\n",
      "        -6.06188104e-02, -6.32381365e-02,  1.19315937e-01,\n",
      "        -4.58611138e-02, -1.01375505e-01, -1.29615039e-01,\n",
      "        -5.36915995e-02, -2.05261000e-02,  2.14269627e-02,\n",
      "        -3.50958817e-02,  7.12625682e-02,  1.03383936e-01,\n",
      "        -8.38937908e-02],\n",
      "       [-2.87593007e-02,  2.49965917e-02,  4.55815122e-02,\n",
      "        -6.77592754e-02,  5.45326658e-02,  4.13336530e-02,\n",
      "        -5.03818840e-02,  1.13973305e-01,  6.94980621e-02,\n",
      "        -5.88780344e-02,  3.98722216e-02, -1.82490319e-03,\n",
      "         4.39534783e-02, -7.81162679e-02,  1.15612186e-01,\n",
      "        -5.57533232e-03],\n",
      "       [-9.39774513e-02, -1.86166335e-02,  6.19216561e-02,\n",
      "         1.02877051e-01,  1.55788502e-02,  9.03072283e-02,\n",
      "         7.19905198e-02,  4.99207247e-03,  5.33093289e-02,\n",
      "         2.44713500e-01,  9.07346830e-02,  3.03945560e-02,\n",
      "         1.53648332e-02,  1.07783057e-01,  1.25826761e-01,\n",
      "        -8.58892277e-02],\n",
      "       [ 1.69889346e-01, -3.96274105e-02,  1.04374379e-01,\n",
      "        -5.93588538e-02,  3.35653692e-01,  1.17426291e-01,\n",
      "        -5.81400581e-02, -2.48716027e-01, -2.27996632e-01,\n",
      "         4.17606831e-02, -5.50717264e-02, -1.19703747e-01,\n",
      "        -1.63300395e-01,  1.14071444e-01,  6.16119765e-02,\n",
      "         2.27755100e-01],\n",
      "       [ 1.24516472e-01, -3.75594236e-02, -8.03561136e-02,\n",
      "        -9.13963374e-03,  8.18242431e-02, -7.61189982e-02,\n",
      "        -1.06771644e-02, -2.00269166e-02,  6.87353089e-02,\n",
      "         2.70474315e-01,  7.34032989e-02,  6.70672487e-03,\n",
      "        -1.35148749e-01,  1.52500674e-01, -2.31720097e-02,\n",
      "        -2.83021876e-03],\n",
      "       [ 3.30204278e-01,  1.02750570e-01, -1.78084940e-01,\n",
      "        -6.25000745e-02,  3.17832857e-01, -1.26077473e-01,\n",
      "        -2.69022658e-02,  6.13554977e-02,  5.76255731e-02,\n",
      "        -2.53143925e-02, -2.32288271e-01, -4.12661210e-02,\n",
      "         3.71524841e-01, -3.37943912e-01, -4.22410429e-01,\n",
      "         1.23784341e-01],\n",
      "       [ 9.63122174e-02, -1.07994445e-01, -4.85881679e-02,\n",
      "        -4.96474048e-03,  1.03272386e-02,  7.90712535e-02,\n",
      "        -3.77003360e-03,  3.32657695e-02,  8.12381227e-03,\n",
      "         4.96867895e-02,  8.96343887e-02, -2.47454420e-02,\n",
      "        -1.64007321e-01,  1.82833746e-01,  5.82522973e-02,\n",
      "        -7.48969018e-02],\n",
      "       [ 2.83747967e-02,  4.39675711e-03, -8.66953135e-02,\n",
      "        -3.71847115e-02,  2.09930807e-01,  2.28102636e-02,\n",
      "        -4.61396985e-02, -6.73523843e-02, -1.59470774e-02,\n",
      "        -4.60960679e-02, -9.49684903e-02, -1.64805222e-02,\n",
      "        -3.28800194e-02, -2.08435375e-02, -9.62865576e-02,\n",
      "         9.17960033e-02],\n",
      "       [ 1.22161601e-02,  3.51461582e-02,  4.54836711e-02,\n",
      "         1.30106807e-02,  5.91816790e-02,  4.16237973e-02,\n",
      "        -1.77741963e-02,  2.70590670e-02, -7.02428818e-02,\n",
      "        -1.49492780e-02,  9.50008929e-02, -8.58682208e-03,\n",
      "         1.43058226e-01, -6.21438771e-02,  1.09365702e-01,\n",
      "         8.54818225e-02],\n",
      "       [-4.45008665e-01, -1.61171526e-01,  8.66259858e-02,\n",
      "        -8.78399014e-02, -3.64567161e-01,  3.64076853e-01,\n",
      "        -9.46177170e-02, -1.24026559e-01,  4.78797197e-01,\n",
      "        -1.47726126e-02,  3.90306681e-01, -7.75855184e-02,\n",
      "         8.84508993e-03,  1.12578057e-01,  4.06851888e-01,\n",
      "         3.87018500e-03],\n",
      "       [-3.35535079e-01, -3.35940391e-01, -6.93244636e-02,\n",
      "        -9.66785476e-02, -4.07398045e-01,  2.26426035e-01,\n",
      "        -6.34709895e-02, -7.10827939e-04,  2.22827360e-01,\n",
      "        -2.10940301e-01,  3.51604521e-01, -5.59077747e-02,\n",
      "        -1.72254890e-01,  8.58038589e-02,  2.71547467e-01,\n",
      "        -2.20940277e-01],\n",
      "       [-4.01159137e-01, -4.22029972e-01,  3.15360464e-02,\n",
      "        -5.62365353e-02, -4.35715206e-02,  3.88411671e-01,\n",
      "        -6.48871958e-02, -2.64324605e-01, -2.44758934e-01,\n",
      "        -7.32401460e-02,  2.26540461e-01,  3.51040065e-02,\n",
      "        -7.75514767e-02,  6.20096251e-02,  2.98746884e-01,\n",
      "         7.18061924e-02],\n",
      "       [-1.25313386e-01, -1.19422570e-01,  8.56489986e-02,\n",
      "         7.78400945e-03, -7.65872896e-02, -6.33861423e-02,\n",
      "        -8.44311155e-03, -7.25403577e-02, -1.68812662e-01,\n",
      "         2.28601471e-02,  1.00741036e-01,  6.04356416e-02,\n",
      "        -6.13365211e-02,  7.62568414e-02,  9.16855708e-02,\n",
      "         6.65599927e-02],\n",
      "       [ 3.27291429e-01, -1.90009192e-01, -7.48454854e-02,\n",
      "        -8.72171894e-02,  7.95909539e-02, -1.99297089e-02,\n",
      "        -4.98084575e-02, -4.34074411e-03,  4.29112554e-01,\n",
      "        -1.24118514e-01, -3.81679200e-02, -5.86776547e-02,\n",
      "        -2.01065212e-01, -3.09514135e-01, -2.74941266e-01,\n",
      "        -1.29626459e-03],\n",
      "       [-2.44066358e-01, -2.60553330e-01,  1.65151149e-01,\n",
      "        -4.26226445e-02, -4.62173641e-01,  2.96064794e-01,\n",
      "        -2.73278896e-02,  1.69499338e-01,  1.83841020e-01,\n",
      "         1.27938434e-01, -9.15801805e-03, -3.14494446e-02,\n",
      "        -5.40974066e-02,  4.10257339e-01,  4.45879459e-01,\n",
      "        -1.49128124e-01],\n",
      "       [-4.93270427e-01, -4.00382698e-01,  1.27475709e-01,\n",
      "        -9.36835706e-02, -4.79098976e-01,  2.38319829e-01,\n",
      "        -6.77318424e-02, -5.41142896e-02,  2.56659597e-01,\n",
      "        -8.74631777e-02,  3.74525338e-01, -2.05021333e-02,\n",
      "        -6.82435706e-02,  7.19554648e-02,  5.45717299e-01,\n",
      "        -8.26172307e-02],\n",
      "       [-9.40368921e-02, -1.59122244e-01, -9.20111462e-02,\n",
      "        -4.51468378e-02, -1.82149217e-01,  1.84132397e-01,\n",
      "        -8.93497989e-02, -4.52809185e-02,  1.17994532e-01,\n",
      "         2.98662507e-03,  1.67066142e-01,  3.63816284e-02,\n",
      "         9.26014632e-02,  1.14370435e-01,  6.45480156e-02,\n",
      "        -1.91095918e-02],\n",
      "       [-1.86999366e-01, -2.85775930e-01, -5.83937392e-02,\n",
      "        -1.01000085e-01, -4.30507690e-01,  1.39080971e-01,\n",
      "        -5.31543009e-02,  8.18942953e-03, -1.20501276e-02,\n",
      "        -2.75454912e-02,  3.59459519e-01, -8.21831375e-02,\n",
      "        -1.48547262e-01,  2.29893595e-01,  2.84411430e-01,\n",
      "        -1.50188133e-01],\n",
      "       [ 1.46072909e-01, -9.02232230e-02, -7.91761354e-02,\n",
      "        -5.62046655e-02, -2.69026943e-02, -4.17043902e-02,\n",
      "        -1.55770814e-03, -6.25851145e-03, -2.13623539e-01,\n",
      "         1.30978256e-01,  9.87788439e-02, -1.02725796e-01,\n",
      "        -2.63038456e-01,  2.26753220e-01,  9.24605802e-02,\n",
      "        -1.23617925e-01],\n",
      "       [-7.12075084e-02, -3.00519541e-02,  8.05199742e-02,\n",
      "        -8.36861208e-02, -2.80400775e-02,  6.53129444e-02,\n",
      "        -3.90989892e-02,  1.70870367e-02,  9.79666784e-02,\n",
      "        -3.66503671e-02,  1.11571968e-01, -2.65373830e-02,\n",
      "         1.35696484e-02, -1.88236788e-03,  2.43572310e-01,\n",
      "        -6.47854134e-02],\n",
      "       [ 1.47692531e-01,  2.19009165e-02, -2.65515521e-02,\n",
      "         1.73627899e-03, -2.24791318e-01,  6.10392727e-02,\n",
      "        -7.29061440e-02, -1.29194200e-01,  2.33290255e-01,\n",
      "         1.43762350e-01,  1.65306717e-01,  1.06320288e-02,\n",
      "        -1.43591508e-01,  2.00824142e-01,  6.49458915e-02,\n",
      "        -3.71108577e-02],\n",
      "       [ 1.88398540e-01, -6.93732798e-02,  8.07386190e-02,\n",
      "         3.99448387e-02,  1.72671266e-02,  1.20804548e-01,\n",
      "        -8.06773528e-02, -1.02308907e-01,  1.23357981e-01,\n",
      "        -9.12787765e-03,  1.65076941e-01, -2.54034288e-02,\n",
      "        -3.13392639e-01,  2.62254119e-01,  2.50371188e-01,\n",
      "         2.49097459e-02],\n",
      "       [ 2.03535393e-01, -5.23580946e-02, -8.67637247e-02,\n",
      "        -3.92492488e-03,  1.57438293e-01,  1.46455005e-01,\n",
      "         3.70718874e-02, -5.32594211e-02,  1.51316091e-01,\n",
      "         2.27574557e-01,  1.41887188e-01,  4.14998125e-04,\n",
      "        -5.63386902e-02,  1.82254598e-01,  9.75236297e-02,\n",
      "        -6.59759715e-02],\n",
      "       [-1.22149393e-01, -2.34196842e-01, -4.61943783e-02,\n",
      "         1.34249376e-02,  2.08006278e-01, -1.64250299e-01,\n",
      "         1.49477040e-02,  1.35362655e-01, -1.29203886e-01,\n",
      "         1.95322279e-02, -2.16524020e-01,  4.62350063e-02,\n",
      "        -3.22968811e-01,  1.09743558e-01, -1.62542328e-01,\n",
      "         3.97053473e-02],\n",
      "       [ 1.46868795e-01,  5.05898893e-02, -2.55291276e-02,\n",
      "        -4.03824076e-02, -1.13159351e-01,  1.50625557e-01,\n",
      "        -5.31456545e-02, -1.81768443e-02,  1.20837815e-01,\n",
      "        -4.55665924e-02,  1.24767333e-01, -1.51097847e-04,\n",
      "        -2.81016052e-01,  2.77567431e-02,  1.60541013e-01,\n",
      "         6.76414147e-02],\n",
      "       [-3.69592726e-01, -1.24168843e-01,  1.30117983e-01,\n",
      "        -8.74853730e-02, -2.19393224e-01,  1.34158193e-03,\n",
      "         7.33002415e-03,  4.08825576e-02,  1.50935963e-01,\n",
      "         2.16398805e-01,  1.76909998e-01, -2.87362952e-02,\n",
      "         5.00853993e-02,  1.36259615e-01,  9.08035785e-02,\n",
      "        -1.09170042e-01]], dtype=float32), array([ 0.304648  ,  0.19852304, -0.2582372 , -0.05554646,  0.05848864,\n",
      "       -0.20741004, -0.03863767,  0.07827416,  0.14138049, -0.01884119,\n",
      "       -0.1474205 , -0.00413412,  0.08759857, -0.06711835, -0.29948145,\n",
      "       -0.11391155], dtype=float32)]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "pesos0 = classificador.layers[0].get_weights()\n",
    "print(pesos0)\n",
    "print(len(pesos0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 0s/step\n"
     ]
    }
   ],
   "source": [
    "previsoes = classificador.predict(previsores_teste)\n",
    "previsoes = previsoes > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7482517482517482"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(classe_teste, previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[52,  4],\n",
       "       [32, 55]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(classe_teste, previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8714 - binary_accuracy: 0.7483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.871420681476593, 0.748251736164093]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado = classificador.evaluate(previsores_teste, classe_teste)\n",
    "resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionando Dropout e aplicando cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criarRede1(): \n",
    "    k.clear_session()\n",
    "    classificador = Sequential([\n",
    "               tf.keras.layers.Dense(units=16, activation = 'relu', kernel_initializer = 'random_uniform', input_dim=30),\n",
    "               tf.keras.layers.Dense(units=16, activation = 'relu', kernel_initializer = 'random_uniform'),\n",
    "               tf.keras.layers.Dropout(0.2),\n",
    "               tf.keras.layers.Dense(units=1, activation = 'sigmoid')])\n",
    "    otimizador = tf.keras.optimizers.Adam(learning_rate = 0.001, weight_decay = 0.0001, clipvalue = 0.5)\n",
    "    classificador.compile(optimizer = otimizador, loss = 'binary_crossentropy', metrics = ['binary_accuracy'])\n",
    "    return classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - 1s 2ms/step - loss: 1.0629 - binary_accuracy: 0.6268\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6624 - binary_accuracy: 0.6585\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5361 - binary_accuracy: 0.7289\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5375 - binary_accuracy: 0.7430\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5576 - binary_accuracy: 0.7218\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5831 - binary_accuracy: 0.7430\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5081 - binary_accuracy: 0.7077\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4861 - binary_accuracy: 0.8063\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4304 - binary_accuracy: 0.8063\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5749 - binary_accuracy: 0.7958\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4915 - binary_accuracy: 0.8063\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5646 - binary_accuracy: 0.7958\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4972 - binary_accuracy: 0.8380\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.6595 - binary_accuracy: 0.8028\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4523 - binary_accuracy: 0.8169\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5028 - binary_accuracy: 0.8169\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4425 - binary_accuracy: 0.8275\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4608 - binary_accuracy: 0.8239\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5004 - binary_accuracy: 0.8345\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4248 - binary_accuracy: 0.8239\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5390 - binary_accuracy: 0.8028\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4619 - binary_accuracy: 0.7993\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4554 - binary_accuracy: 0.8204\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4924 - binary_accuracy: 0.8239\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5344 - binary_accuracy: 0.7852\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4728 - binary_accuracy: 0.8310\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4855 - binary_accuracy: 0.8310\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3961 - binary_accuracy: 0.8239\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.6477 - binary_accuracy: 0.8099\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5002 - binary_accuracy: 0.7746\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.7615 - binary_accuracy: 0.8099\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4722 - binary_accuracy: 0.8063\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4226 - binary_accuracy: 0.8415\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4968 - binary_accuracy: 0.8275\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4878 - binary_accuracy: 0.8063\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.6588 - binary_accuracy: 0.7852\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6993 - binary_accuracy: 0.7746\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4675 - binary_accuracy: 0.7852\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6701 - binary_accuracy: 0.7676\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.7154 - binary_accuracy: 0.7817\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4240 - binary_accuracy: 0.8345\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4939 - binary_accuracy: 0.7993\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5606 - binary_accuracy: 0.7887\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5491 - binary_accuracy: 0.8275\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4665 - binary_accuracy: 0.8063\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4263 - binary_accuracy: 0.7746\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4134 - binary_accuracy: 0.8028\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4473 - binary_accuracy: 0.8204\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3820 - binary_accuracy: 0.8380\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5668 - binary_accuracy: 0.8239\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3733 - binary_accuracy: 0.8380\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 736us/step - loss: 0.3901 - binary_accuracy: 0.8345\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3779 - binary_accuracy: 0.8486\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5020 - binary_accuracy: 0.8310\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4130 - binary_accuracy: 0.8451\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4208 - binary_accuracy: 0.8239\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5532 - binary_accuracy: 0.8486\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4176 - binary_accuracy: 0.8380\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4185 - binary_accuracy: 0.8134\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 815us/step - loss: 0.4347 - binary_accuracy: 0.8063\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4216 - binary_accuracy: 0.8451\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3681 - binary_accuracy: 0.8451\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3904 - binary_accuracy: 0.8486\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.6364 - binary_accuracy: 0.8134\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4777 - binary_accuracy: 0.8380\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4735 - binary_accuracy: 0.8204\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3687 - binary_accuracy: 0.8662\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4538 - binary_accuracy: 0.8451\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3244 - binary_accuracy: 0.8521\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3863 - binary_accuracy: 0.8521\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3918 - binary_accuracy: 0.8627\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3630 - binary_accuracy: 0.8627\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3667 - binary_accuracy: 0.8662\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4359 - binary_accuracy: 0.8627\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3879 - binary_accuracy: 0.8451\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4284 - binary_accuracy: 0.8380\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4451 - binary_accuracy: 0.8310\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3113 - binary_accuracy: 0.8662\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4194 - binary_accuracy: 0.8627\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4754 - binary_accuracy: 0.8451\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3438 - binary_accuracy: 0.8627\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4803 - binary_accuracy: 0.8345\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3414 - binary_accuracy: 0.8627\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5453 - binary_accuracy: 0.8345\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4549 - binary_accuracy: 0.8310\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4402 - binary_accuracy: 0.8556\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4905 - binary_accuracy: 0.8627\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3575 - binary_accuracy: 0.8768\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4804 - binary_accuracy: 0.8521\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4468 - binary_accuracy: 0.8451\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5158 - binary_accuracy: 0.8239\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4400 - binary_accuracy: 0.8275\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4178 - binary_accuracy: 0.8204\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4470 - binary_accuracy: 0.8486\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3544 - binary_accuracy: 0.8662\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4692 - binary_accuracy: 0.8415\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5335 - binary_accuracy: 0.8451\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4712 - binary_accuracy: 0.8486\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3639 - binary_accuracy: 0.8873\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4796 - binary_accuracy: 0.8521\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 1s 2ms/step - loss: 1.4197 - binary_accuracy: 0.5649\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8522 - binary_accuracy: 0.6105\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6762 - binary_accuracy: 0.6421\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6746 - binary_accuracy: 0.6281\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5515 - binary_accuracy: 0.6982\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5133 - binary_accuracy: 0.7228\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4952 - binary_accuracy: 0.7719\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5078 - binary_accuracy: 0.7333\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4573 - binary_accuracy: 0.8246\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5301 - binary_accuracy: 0.7684\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5260 - binary_accuracy: 0.7474\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5020 - binary_accuracy: 0.7930\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5508 - binary_accuracy: 0.8140\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5028 - binary_accuracy: 0.8035\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5571 - binary_accuracy: 0.7930\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4412 - binary_accuracy: 0.8211\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5773 - binary_accuracy: 0.8246\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.6328 - binary_accuracy: 0.7719\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.7748 - binary_accuracy: 0.7754\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5203 - binary_accuracy: 0.8175\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5103 - binary_accuracy: 0.8456\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4781 - binary_accuracy: 0.8316\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4708 - binary_accuracy: 0.7895\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6094 - binary_accuracy: 0.8281\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6846 - binary_accuracy: 0.8316\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.7335 - binary_accuracy: 0.8070\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5215 - binary_accuracy: 0.8316\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.6108 - binary_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3238 - binary_accuracy: 0.8807\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5611 - binary_accuracy: 0.8561\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4097 - binary_accuracy: 0.8491\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4791 - binary_accuracy: 0.8246\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5649 - binary_accuracy: 0.8421\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5287 - binary_accuracy: 0.8351\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4693 - binary_accuracy: 0.8316\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5393 - binary_accuracy: 0.8702\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.6208 - binary_accuracy: 0.8140\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5546 - binary_accuracy: 0.8351\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5265 - binary_accuracy: 0.8561\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.7894 - binary_accuracy: 0.8140\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5525 - binary_accuracy: 0.8140\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5460 - binary_accuracy: 0.8596\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4770 - binary_accuracy: 0.8491\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4063 - binary_accuracy: 0.8842\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4582 - binary_accuracy: 0.8632\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5165 - binary_accuracy: 0.8702\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5266 - binary_accuracy: 0.8175\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4044 - binary_accuracy: 0.8702\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4366 - binary_accuracy: 0.8667\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5556 - binary_accuracy: 0.8351\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4410 - binary_accuracy: 0.8526\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3659 - binary_accuracy: 0.8842\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3893 - binary_accuracy: 0.8947\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5000 - binary_accuracy: 0.8842\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4646 - binary_accuracy: 0.8667\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3474 - binary_accuracy: 0.8912\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5902 - binary_accuracy: 0.8491\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4409 - binary_accuracy: 0.8596\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4627 - binary_accuracy: 0.8667\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3689 - binary_accuracy: 0.8807\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4098 - binary_accuracy: 0.8947\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4717 - binary_accuracy: 0.8842\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4364 - binary_accuracy: 0.8632\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3964 - binary_accuracy: 0.9018\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3630 - binary_accuracy: 0.8912\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3587 - binary_accuracy: 0.9158\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3882 - binary_accuracy: 0.8772\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5795 - binary_accuracy: 0.8632\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4651 - binary_accuracy: 0.8807\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4539 - binary_accuracy: 0.8561\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.6373 - binary_accuracy: 0.9088\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6347 - binary_accuracy: 0.8667\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3907 - binary_accuracy: 0.8807\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.6537 - binary_accuracy: 0.8772\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5112 - binary_accuracy: 0.8386\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6255 - binary_accuracy: 0.8702\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4513 - binary_accuracy: 0.8667\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4036 - binary_accuracy: 0.8982\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.6902 - binary_accuracy: 0.8632\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4999 - binary_accuracy: 0.8842\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6431 - binary_accuracy: 0.8877\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5375 - binary_accuracy: 0.8842\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.7256 - binary_accuracy: 0.8632\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6767 - binary_accuracy: 0.8877\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5468 - binary_accuracy: 0.8561\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8497 - binary_accuracy: 0.8421\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.6543 - binary_accuracy: 0.8596\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4327 - binary_accuracy: 0.8877\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.7312 - binary_accuracy: 0.8526\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5391 - binary_accuracy: 0.8737\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 975us/step - loss: 0.4795 - binary_accuracy: 0.8737\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5349 - binary_accuracy: 0.8667\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4478 - binary_accuracy: 0.8947\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3959 - binary_accuracy: 0.9088\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4428 - binary_accuracy: 0.8947\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6445 - binary_accuracy: 0.8632\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.6265 - binary_accuracy: 0.8842\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3646 - binary_accuracy: 0.9088\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4355 - binary_accuracy: 0.9053\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5598 - binary_accuracy: 0.8842\n",
      "29/29 [==============================] - 0s 927us/step\n",
      "0.8453792933036817\n",
      "0.020817889794909783\n"
     ]
    }
   ],
   "source": [
    "classificador = KerasClassifier(model = criarRede1,\n",
    "                                epochs = 100,\n",
    "                                batch_size = 10)\n",
    "\n",
    "resultados = cross_val_score(estimator = classificador,\n",
    "                             X = previsores, y = classe,\n",
    "                             cv = 2, scoring = 'accuracy')\n",
    "\n",
    "print(resultados.mean())\n",
    "print(resultados.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando Tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criarRede2(optimizer='adam', loss='binary_crossentropy'):\n",
    "    k.clear_session()\n",
    "    classificador = Sequential([\n",
    "               tf.keras.layers.Dense(units=16, activation = 'relu', kernel_initializer = 'random_uniform', input_dim=30),\n",
    "               tf.keras.layers.Dropout(0.2),\n",
    "               tf.keras.layers.Dense(units=16, activation = 'relu', kernel_initializer = 'random_uniform'),\n",
    "               tf.keras.layers.Dropout(0.2),\n",
    "               tf.keras.layers.Dense(units=1, activation = 'sigmoid')])\n",
    "    classificador.compile(optimizer = optimizer, loss = loss, metrics = ['binary_accuracy'])\n",
    "    return classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador = KerasClassifier(build_fn = criarRede2)\n",
    "\n",
    "parametros = {\n",
    "    'batch_size': [10, 30],\n",
    "    'epochs': [50, 100],\n",
    "    'optimizer': ['adam', 'sgd'],\n",
    "    'loss': ['binary_crossentropy', 'hinge']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=classificador, param_grid=parametros, scoring='accuracy', cv=5)\n",
    "grid_search = grid_search.fit(previsores, classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 30, 'epochs': 100, 'loss': 'binary_crossentropy', 'optimizer': 'adam'}\n",
      "0.903400093153237\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando em formato JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/19 [==============================] - 1s 2ms/step - loss: 1.7735 - binary_accuracy: 0.5571\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7837 - binary_accuracy: 0.5923\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5997 - binary_accuracy: 0.6292\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5785 - binary_accuracy: 0.6467\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5354 - binary_accuracy: 0.6555\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5244 - binary_accuracy: 0.6784\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5190 - binary_accuracy: 0.6801\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4992 - binary_accuracy: 0.7047\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4970 - binary_accuracy: 0.6854\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4700 - binary_accuracy: 0.7276\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.4468 - binary_accuracy: 0.7803\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4706 - binary_accuracy: 0.7452\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.4540 - binary_accuracy: 0.7979\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.3980 - binary_accuracy: 0.8155\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3811 - binary_accuracy: 0.8348\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3898 - binary_accuracy: 0.8243\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.4235 - binary_accuracy: 0.7944\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.3694 - binary_accuracy: 0.8418\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 922us/step - loss: 0.3540 - binary_accuracy: 0.8453\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3315 - binary_accuracy: 0.8594\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3256 - binary_accuracy: 0.8858\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 677us/step - loss: 0.3345 - binary_accuracy: 0.8471\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.3211 - binary_accuracy: 0.8594\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 886us/step - loss: 0.3002 - binary_accuracy: 0.8699\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.3007 - binary_accuracy: 0.8787\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3052 - binary_accuracy: 0.8664\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2569 - binary_accuracy: 0.9069\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2803 - binary_accuracy: 0.8840\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 996us/step - loss: 0.3018 - binary_accuracy: 0.8787\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2640 - binary_accuracy: 0.9051\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2693 - binary_accuracy: 0.9086\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 720us/step - loss: 0.3107 - binary_accuracy: 0.8629\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2697 - binary_accuracy: 0.8998\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3037 - binary_accuracy: 0.8805\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2587 - binary_accuracy: 0.8910\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2456 - binary_accuracy: 0.9086\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 664us/step - loss: 0.2366 - binary_accuracy: 0.9086\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2168 - binary_accuracy: 0.9209\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2336 - binary_accuracy: 0.9033\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2337 - binary_accuracy: 0.9086\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2183 - binary_accuracy: 0.9192\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2348 - binary_accuracy: 0.9033\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2378 - binary_accuracy: 0.9069\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2439 - binary_accuracy: 0.9016\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2401 - binary_accuracy: 0.9121\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2294 - binary_accuracy: 0.9121\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2160 - binary_accuracy: 0.9209\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2212 - binary_accuracy: 0.9086\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2265 - binary_accuracy: 0.8998\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2399 - binary_accuracy: 0.8981\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2196 - binary_accuracy: 0.9104\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2180 - binary_accuracy: 0.9033\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 757us/step - loss: 0.2056 - binary_accuracy: 0.9156\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2084 - binary_accuracy: 0.9139\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2024 - binary_accuracy: 0.9156\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2052 - binary_accuracy: 0.9121\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1971 - binary_accuracy: 0.9209\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2047 - binary_accuracy: 0.9069\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1956 - binary_accuracy: 0.9227\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.1987 - binary_accuracy: 0.9297\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2382 - binary_accuracy: 0.8946\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2282 - binary_accuracy: 0.9121\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2447 - binary_accuracy: 0.9069\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 826us/step - loss: 0.2021 - binary_accuracy: 0.9227\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2110 - binary_accuracy: 0.9174\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 886us/step - loss: 0.1706 - binary_accuracy: 0.9315\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2044 - binary_accuracy: 0.9297\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2102 - binary_accuracy: 0.9121\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.1999 - binary_accuracy: 0.9209\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2022 - binary_accuracy: 0.9262\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.1750 - binary_accuracy: 0.9315\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.1987 - binary_accuracy: 0.9104\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.1916 - binary_accuracy: 0.9385\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2071 - binary_accuracy: 0.9209\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1909 - binary_accuracy: 0.9139\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1950 - binary_accuracy: 0.9227\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2009 - binary_accuracy: 0.9209\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.1891 - binary_accuracy: 0.9279\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.1933 - binary_accuracy: 0.9209\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1719 - binary_accuracy: 0.9227\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.1849 - binary_accuracy: 0.9227\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.1722 - binary_accuracy: 0.9332\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1941 - binary_accuracy: 0.9262\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2093 - binary_accuracy: 0.9332\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2042 - binary_accuracy: 0.9174\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 842us/step - loss: 0.2313 - binary_accuracy: 0.9016\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.1868 - binary_accuracy: 0.9315\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.1450 - binary_accuracy: 0.9402\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 623us/step - loss: 0.1606 - binary_accuracy: 0.9297\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1780 - binary_accuracy: 0.9367\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1674 - binary_accuracy: 0.9332\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.1579 - binary_accuracy: 0.9438\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1873 - binary_accuracy: 0.9315\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.1813 - binary_accuracy: 0.9227\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.1789 - binary_accuracy: 0.9315\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.1734 - binary_accuracy: 0.9279\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.1768 - binary_accuracy: 0.9244\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1596 - binary_accuracy: 0.9332\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.1757 - binary_accuracy: 0.9315\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1923 - binary_accuracy: 0.9192\n"
     ]
    }
   ],
   "source": [
    "classificador = Sequential()\n",
    "\n",
    "classificador.add(Dense(units = 16, activation = 'relu', \n",
    "                        kernel_initializer = 'random_uniform', input_dim = 30))\n",
    "classificador.add(Dropout(0.2))\n",
    "classificador.add(Dense(units = 16, activation = 'relu', \n",
    "                        kernel_initializer = 'random_uniform'))\n",
    "classificador.add(Dropout(0.2))\n",
    "classificador.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "classificador.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n",
    "                      metrics = ['binary_accuracy'])\n",
    "\n",
    "classificador.fit(previsores, classe, batch_size = 30, epochs = 100)\n",
    "\n",
    "classificador_json = classificador.to_json()\n",
    "with open('classificador_breast.json', 'w') as json_file:\n",
    "    json_file.write(classificador_json)\n",
    "classificador.save_weights('classificador_breast.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando rede neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = open('classificador_breast.json', 'r')\n",
    "estrutura_rede = arquivo.read()\n",
    "arquivo.close()\n",
    "\n",
    "classificador = model_from_json(estrutura_rede)\n",
    "classificador.load_weights('classificador_breast.h5')\n",
    "\n",
    "novo = np.array([[15.80, 8.34, 118, 900, 0.10, 0.26, 0.08, 0.134, 0.178,\n",
    "                  0.20, 0.05, 1098, 0.87, 4500, 145.2, 0.005, 0.04, 0.05, 0.015,\n",
    "                  0.03, 0.007, 23.15, 16.64, 178.5, 2018, 0.14, 0.185,\n",
    "                  0.84, 158, 0.363]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1213 - binary_accuracy: 0.9455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12133578211069107, 0.945518434047699]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsores = pd.read_csv('entradas_breast.csv')\n",
    "classe = pd.read_csv('saidas_breast.csv')\n",
    "classificador.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "classificador.evaluate(previsores, classe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
